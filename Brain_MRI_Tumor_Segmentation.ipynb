{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as keras\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "image_height = 512\n",
    "image_width = 512\n",
    "image_depth = 1\n",
    "epochs=100\n",
    "batch_size = 32\n",
    "epoch_index = [i for i in range(1, epochs+1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "images = np.load(os.path.join(\"Brain_MRI_data1\", \"images.npy\"), allow_pickle=True)\n",
    "masks = np.load(os.path.join(\"Brain_MRI_data1\", \"masks.npy\"), allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Change all image to grey"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m image_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m image \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[43mimages\u001B[49m):\n\u001B[1;32m      3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimsave(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBrain_MRI_Segment_image\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(image_index)), image, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m     image_index \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "image_index = 0\n",
    "for image in tqdm(images):\n",
    "    plt.imsave(os.path.join(\"Brain_MRI_Segment_image\", \"image_{}.jpg\".format(image_index)), image, cmap='gray')\n",
    "    image_index += 1\n",
    "\n",
    "mask_index = 0\n",
    "for mask in tqdm(masks):\n",
    "    plt.imsave(os.path.join(\"Brain_MRI_Segment_mask\", \"mask_{}.jpg\".format(mask_index)), mask, cmap='gray')\n",
    "    mask_index += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3064/3064 [00:03<00:00, 771.76it/s]\n",
      "100%|██████████| 3064/3064 [00:03<00:00, 926.20it/s] \n"
     ]
    }
   ],
   "source": [
    "image_dir_name = \"Brain_MRI_Segment_image\"\n",
    "mask_dir_name = \"Brain_MRI_Segment_mask\"\n",
    "image_list = list()\n",
    "mask_list = list()\n",
    "\n",
    "images_dir = sorted(os.listdir(image_dir_name))\n",
    "for image in tqdm(images_dir):\n",
    "    current_image = cv2.imread(os.path.join(image_dir_name, image), cv2.IMREAD_GRAYSCALE)\n",
    "    current_image = cv2.resize(current_image, (image_height, image_width))\n",
    "    current_image_180 = cv2.rotate(current_image, cv2.ROTATE_180)\n",
    "    current_image_r90 = cv2.rotate(current_image, cv2.ROTATE_90_CLOCKWISE)\n",
    "    current_image_l90 = cv2.rotate(current_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    image_list.append(current_image)\n",
    "    image_list.append(current_image_180)\n",
    "    image_list.append(current_image_r90)\n",
    "    image_list.append(current_image_l90)\n",
    "\n",
    "\n",
    "\n",
    "masks_dir = sorted(os.listdir(mask_dir_name))\n",
    "for mask in tqdm(masks_dir):\n",
    "    current_mask = cv2.imread(os.path.join(mask_dir_name, mask), cv2.IMREAD_GRAYSCALE)\n",
    "    current_mask = cv2.resize(current_mask, (image_height, image_width))\n",
    "    current_mask_180 = cv2.rotate(current_mask, cv2.ROTATE_180)\n",
    "    current_mask_r90 = cv2.rotate(current_mask, cv2.ROTATE_90_CLOCKWISE)\n",
    "    current_mask_l90 = cv2.rotate(current_mask, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    mask_list.append(current_mask)\n",
    "    mask_list.append(current_mask_180)\n",
    "    mask_list.append(current_mask_r90)\n",
    "    mask_list.append(current_mask_l90)\n",
    "\n",
    "\n",
    "features = np.array(image_list)/255.0\n",
    "masks = np.array(mask_list)/255.0\n",
    "\n",
    "\n",
    "# new_list_of_features = list()\n",
    "# for arr in tqdm(image_list):\n",
    "#     new_feature = arr.reshape((image_height, image_width, 1))\n",
    "#     new_list_of_features.append(new_feature)\n",
    "#\n",
    "# new_list_of_features = np.array(new_list_of_features)\n",
    "#\n",
    "# new_list_of_masks = list()\n",
    "# for arr in tqdm(mask_list):\n",
    "#     new_mask = arr.reshape((image_height, image_width, 1))\n",
    "#     new_list_of_masks.append(new_mask)\n",
    "#\n",
    "# new_list_of_masks = np.array(new_list_of_masks)\n",
    "features = features.reshape((features.shape[0], features.shape[1], features.shape[2], 1))\n",
    "masks = masks.reshape((masks.shape[0], masks.shape[1], masks.shape[2], 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image dimension: (12256, 512, 512, 1), label dimension: (12256, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"image dimension: {}, label dimension: {}\".format(features.shape, masks.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train, Test, Validation Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m train_generator \u001B[38;5;241m=\u001B[39m ImageDataGenerator(validation_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m)\n\u001B[1;32m      5\u001B[0m test_generator \u001B[38;5;241m=\u001B[39m ImageDataGenerator()\n\u001B[0;32m----> 7\u001B[0m train_df \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtraining\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m validation_df \u001B[38;5;241m=\u001B[39m train_generator\u001B[38;5;241m.\u001B[39mflow(X_train, y_train, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, subset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m\"\u001B[39m, seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      9\u001B[0m test_df \u001B[38;5;241m=\u001B[39m train_generator\u001B[38;5;241m.\u001B[39mflow(X_test, y_test, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/CS_HW/lib/python3.8/site-packages/keras_preprocessing/image/image_data_generator.py:421\u001B[0m, in \u001B[0;36mImageDataGenerator.flow\u001B[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001B[0m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflow\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    369\u001B[0m          x,\n\u001B[1;32m    370\u001B[0m          y\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    377\u001B[0m          save_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpng\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    378\u001B[0m          subset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    379\u001B[0m     \u001B[38;5;124;03m\"\"\"Takes data & label arrays, generates batches of augmented data.\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \n\u001B[1;32m    381\u001B[0m \u001B[38;5;124;03m    # Arguments\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;124;03m            If `y` is None, only the NumPy array `x` is returned.\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 421\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mNumpyArrayIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_to_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_to_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/CS_HW/lib/python3.8/site-packages/keras_preprocessing/image/numpy_array_iterator.py:104\u001B[0m, in \u001B[0;36mNumpyArrayIterator.__init__\u001B[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001B[0m\n\u001B[1;32m     99\u001B[0m split_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(x) \u001B[38;5;241m*\u001B[39m image_data_generator\u001B[38;5;241m.\u001B[39m_validation_split)\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m\n\u001B[1;32m    102\u001B[0m     np\u001B[38;5;241m.\u001B[39marray_equal(np\u001B[38;5;241m.\u001B[39munique(y[:split_idx]),\n\u001B[1;32m    103\u001B[0m                    np\u001B[38;5;241m.\u001B[39munique(y[split_idx:]))):\n\u001B[0;32m--> 104\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining and validation subsets \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    105\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhave different number of classes after \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    106\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe split. If your numpy arrays are \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    107\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msorted by the label, you might want \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    108\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto shuffle them.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m subset \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    111\u001B[0m     x \u001B[38;5;241m=\u001B[39m x[:split_idx]\n",
      "\u001B[0;31mValueError\u001B[0m: Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, masks, test_size=0.25, random_state=42, shuffle=True)\n",
    "tf.cast(X_test, tf.float32)\n",
    "tf.cast(y_test, tf.float32)\n",
    "train_generator = ImageDataGenerator(validation_split=0.25)\n",
    "test_generator = ImageDataGenerator()\n",
    "\n",
    "train_df = train_generator.flow(X_train, y_train, batch_size=batch_size, subset=\"training\")\n",
    "validation_df = train_generator.flow(X_train, y_train, batch_size=batch_size, subset=\"validation\", seed=42)\n",
    "test_df = train_generator.flow(X_test, y_test, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define U-Net Model and Loss Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = keras.flatten(y_true)\n",
    "    y_pred_f = keras.flatten(y_pred)\n",
    "    intersection = keras.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def unet(input_size=(256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 512, 512, 32  320         ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 512, 512, 32  9248        ['conv2d_76[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_16 (MaxPooling2D  (None, 256, 256, 32  0          ['conv2d_77[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 256, 256, 64  18496       ['max_pooling2d_16[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_78[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_17 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_79[0][0]']              \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 128, 128, 12  73856       ['max_pooling2d_17[0][0]']       \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_80[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_18 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_81[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 64, 64, 256)  295168      ['max_pooling2d_18[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_82[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_19 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_83[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 32, 32, 512)  1180160     ['max_pooling2d_19[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 32, 32, 512)  2359808     ['conv2d_84[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_16 (Conv2DTra  (None, 64, 64, 256)  524544     ['conv2d_85[0][0]']              \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 64, 64, 512)  0           ['conv2d_transpose_16[0][0]',    \n",
      "                                                                  'conv2d_83[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_16[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 64, 64, 256)  590080      ['conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_17 (Conv2DTra  (None, 128, 128, 12  131200     ['conv2d_87[0][0]']              \n",
      " nspose)                        8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 128, 128, 25  0           ['conv2d_transpose_17[0][0]',    \n",
      "                                6)                                'conv2d_81[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_17[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_88[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_18 (Conv2DTra  (None, 256, 256, 64  32832      ['conv2d_89[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_18 (Concatenate)   (None, 256, 256, 12  0           ['conv2d_transpose_18[0][0]',    \n",
      "                                8)                                'conv2d_79[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_18[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_90[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_19 (Conv2DTra  (None, 512, 512, 32  8224       ['conv2d_91[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_19 (Concatenate)   (None, 512, 512, 64  0           ['conv2d_transpose_19[0][0]',    \n",
      "                                )                                 'conv2d_77[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 512, 512, 32  18464       ['concatenate_19[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 512, 512, 32  9248        ['conv2d_92[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 512, 512, 1)  33          ['conv2d_93[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,759,521\n",
      "Trainable params: 7,759,521\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Unet = unet(input_size=(image_height,image_width,1))\n",
    "model_Unet.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef, 'binary_accuracy'])\n",
    "model_Unet.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/wangyaya/opt/anaconda3/envs/CS_HW/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/ipykernel_31580/2660477695.py\", line 8, in dice_coef_loss  *\n        return -dice_coef(y_true, y_pred)\n    File \"/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/ipykernel_31580/2660477695.py\", line 4, in dice_coef  *\n        intersection = keras.sum(y_true_f * y_pred_f)\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type uint8 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[37], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m unet_history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_Unet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_df\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_df\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/CS_HW/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/__autograph_generated_file06cgb4ig.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/__autograph_generated_file6x6u0__i.py:12\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dice_coef_loss\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     11\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(dice_coef), (ag__\u001B[38;5;241m.\u001B[39mld(y_true), ag__\u001B[38;5;241m.\u001B[39mld(y_pred)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope))\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/__autograph_generated_filedstze5jx.py:12\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__dice_coef\u001B[0;34m(y_true, y_pred)\u001B[0m\n\u001B[1;32m     10\u001B[0m y_true_f \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(keras)\u001B[38;5;241m.\u001B[39mflatten, (ag__\u001B[38;5;241m.\u001B[39mld(y_true),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     11\u001B[0m y_pred_f \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(keras)\u001B[38;5;241m.\u001B[39mflatten, (ag__\u001B[38;5;241m.\u001B[39mld(y_pred),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m---> 12\u001B[0m intersection \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(keras)\u001B[38;5;241m.\u001B[39msum, ((ag__\u001B[38;5;241m.\u001B[39mld(y_true_f) \u001B[38;5;241m*\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(y_pred_f)),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: in user code:\n\n    File \"/Users/wangyaya/opt/anaconda3/envs/CS_HW/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/ipykernel_31580/2660477695.py\", line 8, in dice_coef_loss  *\n        return -dice_coef(y_true, y_pred)\n    File \"/var/folders/_t/5xwcj3s913b6rjc1d1nq30m80000gn/T/ipykernel_31580/2660477695.py\", line 4, in dice_coef  *\n        intersection = keras.sum(y_true_f * y_pred_f)\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type uint8 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "unet_history = model_Unet.fit(train_df,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=validation_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
